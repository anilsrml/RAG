# RAG PDF Chatbot

PDF dokÃ¼manlarÄ±nÄ± yÃ¼kleyerek, lokalde Ã§alÄ±ÅŸan bir dil modeli ile dokÃ¼man iÃ§eriÄŸi hakkÄ±nda soru sorabileceÄŸiniz akÄ±llÄ± bir sohbet botu.

## Ã–zellikler

- ğŸ“„ PDF dosyalarÄ±nÄ± yÃ¼kleme ve iÅŸleme
- ğŸ” Semantik arama ile ilgili bilgileri bulma
- ğŸ’¬ Lokal LLM (Ollama) ile sohbet
- ğŸ“š Kaynak gÃ¶sterimi (sayfa numaralarÄ± ve benzerlik skorlarÄ±)
- ğŸ”’ Tamamen lokal Ã§alÄ±ÅŸma (veri gÃ¼venliÄŸi)

## Gereksinimler

- Python 3.10+
- Ollama kurulu ve Ã§alÄ±ÅŸÄ±r durumda
- Mistral modeli Ollama'da yÃ¼klÃ¼ olmalÄ±

## Kurulum

### 1. Ollama Kurulumu

Ollama'yÄ± [ollama.ai](https://ollama.ai) adresinden indirip kurun.

Mistral modelini yÃ¼kleyin:
```bash
ollama pull mistral
```

Ollama'nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun:
```bash
ollama serve
```

### 2. Proje Kurulumu

```bash
# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt

# Environment dosyasÄ±nÄ± oluÅŸtur
cp .env.example .env

# Gerekirse .env dosyasÄ±nÄ± dÃ¼zenleyin
```

### 3. YapÄ±landÄ±rma

`config.yaml` dosyasÄ±nÄ± ihtiyacÄ±nÄ±za gÃ¶re dÃ¼zenleyebilirsiniz:
- Chunk boyutu
- Top-K deÄŸeri
- LLM modeli
- Embedding modeli

## KullanÄ±m

### Ä°nteraktif Mod

```bash
python app.py
```

MenÃ¼den seÃ§im yapÄ±n:
1. PDF YÃ¼kle
2. Sohbet BaÅŸlat
3. Ã‡Ä±kÄ±ÅŸ

### Komut SatÄ±rÄ± Modu

```bash
# PDF yÃ¼kle
python app.py load document.pdf

# PDF yÃ¼kle ve sohbet baÅŸlat
python app.py load document.pdf --chat

# Ã–nceden yÃ¼klenmiÅŸ PDF ile sohbet
python app.py chat
```

### Sohbet Ä°Ã§i Komutlar

- Normal soru sorun: `PDF'de ana konu nedir?`
- Ã‡Ä±kmak iÃ§in: `/exit`, `/quit` veya `/Ã§Ä±kÄ±ÅŸ`

## Proje YapÄ±sÄ±

```
rag-pdf-chatbot/
â”œâ”€â”€ app.py                      # Ana CLI uygulamasÄ±
â”œâ”€â”€ requirements.txt            # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ config.yaml                 # YapÄ±landÄ±rma dosyasÄ±
â”œâ”€â”€ .env                        # Environment variables
â”œâ”€â”€ README.md                   # Bu dosya
â”œâ”€â”€ PRD.md                      # ÃœrÃ¼n gereksinimleri dokÃ¼manÄ±
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pdf_processor.py        # PDF yÃ¼kleme ve iÅŸleme
â”‚   â”œâ”€â”€ text_splitter.py        # Chunking logic
â”‚   â”œâ”€â”€ embeddings.py           # Embedding oluÅŸturma
â”‚   â”œâ”€â”€ vector_store.py         # ChromaDB iÅŸlemleri
â”‚   â”œâ”€â”€ llm_handler.py          # Ollama LLM iÅŸlemleri
â”‚   â”œâ”€â”€ rag_chain.py            # RAG pipeline
â”‚   â””â”€â”€ prompt_templates.py     # Prompt ÅŸablonlarÄ±
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/                # YÃ¼klenen PDF'ler (opsiyonel)
â”‚   â””â”€â”€ chroma_db/              # ChromaDB persist directory
â”‚
â””â”€â”€ tests/
    â””â”€â”€ (test dosyalarÄ±)
```

## Teknik Detaylar

### Mimari

1. **PDF Ä°ÅŸleme**: pdfplumber ile metin Ã§Ä±karma
2. **Chunking**: LangChain RecursiveCharacterTextSplitter
3. **Embedding**: sentence-transformers (all-MiniLM-L6-v2)
4. **VektÃ¶r DB**: ChromaDB (cosine similarity)
5. **LLM**: Ollama (Mistral modeli)
6. **RAG Pipeline**: Query â†’ Embed â†’ Search â†’ Generate

### VarsayÄ±lan Ayarlar

- Chunk size: 500 karakter
- Chunk overlap: 150 karakter
- Top-K: 5 chunk
- Temperature: 0.7
- Similarity threshold: 0.5

## Sorun Giderme

### Ollama BaÄŸlantÄ± HatasÄ±

```
Ollama API'ye baÄŸlanÄ±lamadÄ±
```

**Ã‡Ã¶zÃ¼m**: Ollama'nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun:
```bash
ollama serve
```

### Model BulunamadÄ± HatasÄ±

```
Model 'mistral' bulunamadÄ±
```

**Ã‡Ã¶zÃ¼m**: Modeli yÃ¼kleyin:
```bash
ollama pull mistral
```

### PDF Metin Ã‡Ä±karÄ±lamadÄ±

BazÄ± PDF'ler gÃ¶rÃ¼ntÃ¼ tabanlÄ±dÄ±r ve OCR gerektirebilir. Bu durumda:
- PDF'i OCR ile iÅŸleyin
- Veya metin tabanlÄ± bir PDF kullanÄ±n

## Lisans

Bu proje eÄŸitim amaÃ§lÄ±dÄ±r.

## KatkÄ±da Bulunma

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! LÃ¼tfen PR gÃ¶ndermeden Ã¶nce kod standartlarÄ±na uyduÄŸunuzdan emin olun.
